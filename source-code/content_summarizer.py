import requests
import logging
from typing import Optional, Dict
from bs4 import BeautifulSoup
from config import HEADERS

logger = logging.getLogger(__name__)

class ContentSummarizer:
    """è§†é¢‘å†…å®¹æ€»ç»“å™¨"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update(HEADERS)
    
    def extract_video_info(self, video_detail: Dict) -> Dict:
        """ä»è§†é¢‘è¯¦æƒ…ä¸­æå–å…³é”®ä¿¡æ¯"""
        try:
            # åŸºæœ¬ä¿¡æ¯
            title = video_detail.get('title', '')
            desc = video_detail.get('desc', '')
            duration = video_detail.get('duration', 0)
            view_count = video_detail.get('stat', {}).get('view', 0)
            
            # æ ‡ç­¾ä¿¡æ¯
            tags = [tag.get('tag_name', '') for tag in video_detail.get('tag', [])]
            
            # åˆ†Pä¿¡æ¯ (å¦‚æœæœ‰)
            pages = video_detail.get('pages', [])
            
            return {
                'title': title,
                'description': desc,
                'duration': duration,
                'view_count': view_count,
                'tags': tags,
                'pages': len(pages),
                'has_multiple_parts': len(pages) > 1
            }
            
        except Exception as e:
            logger.error(f"Error extracting video info: {e}")
            return {}
    
    def generate_summary(self, video: Dict, video_detail: Optional[Dict] = None) -> str:
        """ç”Ÿæˆè§†é¢‘å†…å®¹æ‘˜è¦"""
        try:
            title = video.get('title', '')
            description = video.get('description', '')
            video_url = video.get('video_url', '')
            
            # æ„å»ºæ‘˜è¦
            summary_parts = []
            
            # æ ‡é¢˜
            summary_parts.append(f"ğŸ“º **{title}**")
            
            # è·å–æè¿°å†…å®¹
            desc = description
            tags = []
            
            # å¦‚æœæœ‰è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨æ›´ä¸°å¯Œçš„æè¿°
            if video_detail:
                video_info = self.extract_video_info(video_detail)
                desc = video_info.get('description', description)
                tags = video_info.get('tags', [])
            
            # æè¿° (æ¸…ç†åçš„å†…å®¹ï¼Œè½¬æ¢ä¸ºbullet pointsæ ¼å¼)
            if desc and desc.strip():
                clean_desc = self._clean_description(desc)
                if clean_desc:
                    summary_parts.append(f"\n\nğŸ“‹ **å†…å®¹æ¦‚è¦ï¼š**\n{clean_desc}")
            
            # æ ‡ç­¾ï¼ˆä»…åœ¨æœ‰è¯¦ç»†ä¿¡æ¯æ—¶æ˜¾ç¤ºï¼‰
            if tags:
                relevant_tags = [tag for tag in tags[:5] if tag]  # å–å‰5ä¸ªæ ‡ç­¾
                if relevant_tags:
                    summary_parts.append(f"\n\nğŸ·ï¸ **ç›¸å…³æ ‡ç­¾ï¼š** {' | '.join(relevant_tags)}")
            
            # è§‚çœ‹é“¾æ¥ - è¿™æ˜¯å”¯ä¸€ä¿ç•™çš„é“¾æ¥
            summary_parts.append(f"\n\nğŸ”— **è§‚çœ‹é“¾æ¥ï¼š** {video_url}")
            
            return "".join(summary_parts)
                
        except Exception as e:
            logger.error(f"Error generating summary: {e}")
            return f"ğŸ“º {video.get('title', 'æœªçŸ¥æ ‡é¢˜')}\nğŸ”— {video.get('video_url', '')}"
    
    def _clean_description(self, description: str) -> str:
        """æ¸…ç†æè¿°æ–‡æœ¬å¹¶æŒ‰æ—¶é—´ä¿¡æ¯åˆ†å‰²ä¸ºbullet points"""
        try:
            import re
            
            # ç§»é™¤HTMLæ ‡ç­¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if '<' in description and '>' in description:
                soup = BeautifulSoup(description, 'html.parser')
                clean_text = soup.get_text()
            else:
                clean_text = description
            
            # å°† â¬› æ›¿æ¢ä¸ºæ¢è¡Œç¬¦
            clean_text = clean_text.replace('â¬›', '\n\n')
            
            # ç§»é™¤æ‰€æœ‰emojiè¡¨æƒ…ç¬¦å·ï¼ˆç²¾ç¡®èŒƒå›´ï¼Œé¿å…è¯¯åˆ æ±‰å­—ï¼‰
            # æ±‰å­—èŒƒå›´: U+4E00-U+9FFFï¼Œè¦é¿å…è¿™ä¸ªèŒƒå›´
            emoji_pattern = re.compile(
                "["
                "\U0001F600-\U0001F64F"  # emoticons (ğŸ˜€-ğŸ™)
                "\U0001F300-\U0001F5FF"  # symbols & pictographs (ğŸŒ€-ğŸ—¿) 
                "\U0001F680-\U0001F6FF"  # transport & map symbols (ğŸš€-ğŸ›¿)
                "\U0001F1E0-\U0001F1FF"  # flags (ğŸ‡ -ğŸ‡¿)
                "\U0001F900-\U0001F9FF"  # supplemental symbols (ğŸ¤€-ğŸ§¿)
                "\U0001FA70-\U0001FAFF"  # symbols and pictographs extended-A
                "\U00002600-\U000026FF"  # miscellaneous symbols (â˜€-â›¿) 
                "\U00002700-\U000027BF"  # dingbats (âœ€-â¿)
                "\U0001F000-\U0001F02F"  # mahjong tiles
                "\U0001F0A0-\U0001F0FF"  # playing cards
                "]+", flags=re.UNICODE)
            clean_text = emoji_pattern.sub('', clean_text)
            
            # ç§»é™¤æ‰€æœ‰é“¾æ¥ä¿¡æ¯
            # ç§»é™¤ http/https é“¾æ¥
            clean_text = re.sub(r'https?://[^\s\n\r\t]+', ' ', clean_text)
            
            # ç§»é™¤ www å¼€å¤´çš„é“¾æ¥
            clean_text = re.sub(r'www\.[^\s\n\r\t]+', ' ', clean_text)
            
            # ç§»é™¤é‚®ç®±
            clean_text = re.sub(r'\S+@\S+\.\S+', ' ', clean_text)
            
            # ç§»é™¤Bç«™ç›¸å…³é“¾æ¥æ ¼å¼
            clean_text = re.sub(r'BV[0-9A-Za-z]+', ' ', clean_text)
            clean_text = re.sub(r'av[0-9]+', ' ', clean_text)
            
            # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
            clean_text = re.sub(r'\s+', ' ', clean_text)
            
            # ç§»é™¤ä¸€äº›å¸¸è§çš„æ— ç”¨ä¿¡æ¯
            unwanted_phrases = [
                'ç‚¹å‡»å±•å¼€',
                'å±•å¼€å…¨éƒ¨',
                'æ”¶èµ·',
                'æ›´å¤šç²¾å½©å†…å®¹',
                'å…³æ³¨æˆ‘ä»¬',
                'è®¢é˜…é¢‘é“',
                'é“¾æ¥ï¼š',
                'ç½‘å€ï¼š',
                'åœ°å€ï¼š',
                'å®˜ç½‘ï¼š',
                'è¯¦æƒ…ï¼š',
                'æŸ¥çœ‹æ›´å¤š',
                'ç‚¹å‡»æŸ¥çœ‹',
                'å¤åˆ¶é“¾æ¥',
                'åˆ†äº«é“¾æ¥'
            ]
            
            for phrase in unwanted_phrases:
                clean_text = clean_text.replace(phrase, '')
            
            # æŒ‰æ—¶é—´ä¿¡æ¯åˆ†å‰²å†…å®¹ï¼šå¯»æ‰¾ ": {æ—¶é—´ä¿¡æ¯}" æ¨¡å¼
            # æ”¹è¿›çš„æ—¶é—´æ¨¡å¼åŒ¹é…é€»è¾‘
            time_pattern = r'([^:\n]+):\s*(\d{1,2}:\d{2}|\d{4}-\d{1,2}-\d{1,2}|\d{1,2}æœˆ\d{1,2}æ—¥|\d{1,2}/\d{1,2}|\d{1,2}-\d{1,2}|ä»Šå¤©|æ˜¨å¤©|æ˜å¤©|æœ¬å‘¨|ä¸Šå‘¨|ä¸‹å‘¨)'
            
            # å¯»æ‰¾æ‰€æœ‰åŒ¹é…çš„æ—¶é—´æ¨¡å¼
            time_matches = list(re.finditer(time_pattern, clean_text))
            bullet_points = []
            
            if time_matches:
                # æŒ‰ç…§åŒ¹é…çš„ä½ç½®åˆ†å‰²æ–‡æœ¬
                last_end = 0
                
                for match in time_matches:
                    # è·å–åŒ¹é…å‰çš„å†…å®¹ä½œä¸ºå‰ç½®æè¿°
                    prefix_content = clean_text[last_end:match.start()].strip()
                    
                    # è·å–åŒ¹é…çš„æ ‡é¢˜å’Œæ—¶é—´
                    title_part = match.group(1).strip()
                    time_part = match.group(2).strip()
                    
                    # è·å–åŒ¹é…åçš„å†…å®¹ï¼ˆåˆ°ä¸‹ä¸€ä¸ªåŒ¹é…æˆ–æ–‡æœ¬ç»“å°¾ï¼‰
                    next_match_start = time_matches[time_matches.index(match) + 1].start() if time_matches.index(match) + 1 < len(time_matches) else len(clean_text)
                    content_part = clean_text[match.end():next_match_start].strip()
                    
                    # æ„å»ºæ¡ç›®
                    if title_part and content_part:
                        # æ¸…ç†å†…å®¹ï¼Œç§»é™¤å¤šä½™çš„æ¢è¡Œå’Œç©ºæ ¼
                        content_part = re.sub(r'\s+', ' ', content_part)
                        entry = f"{title_part} ({time_part}): {content_part}"
                    elif title_part:
                        entry = f"{title_part} ({time_part})"
                    else:
                        continue
                    
                    if len(entry.strip()) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„æ¡ç›®
                        bullet_points.append(entry.strip())
                    
                    last_end = next_match_start
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¶é—´æ¨¡å¼ï¼Œå°è¯•å…¶ä»–åˆ†å‰²æ–¹å¼
            if not bullet_points:
                # æŒ‰æ®µè½åˆ†å‰²
                paragraphs = clean_text.split('\n')
                for para in paragraphs:
                    para = para.strip()
                    if para and len(para) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„æ®µè½
                        # æ¸…ç†æ®µè½å†…å®¹
                        if not re.match(r'^[^\w\u4e00-\u9fff]*$', para):
                            bullet_points.append(para)
            
            # å¦‚æœä»ç„¶æ²¡æœ‰æ¡ç›®ï¼Œä½¿ç”¨åŸå§‹æ¸…ç†é€»è¾‘
            if not bullet_points:
                lines = clean_text.split('\n')
                for line in lines:
                    line = line.strip()
                    if line and len(line) > 3 and not re.match(r'^[^\w\u4e00-\u9fff]*$', line):
                        bullet_points.append(line)
            
            # æ ¼å¼åŒ–ä¸ºbullet points
            if bullet_points:
                # é™åˆ¶æ¡ç›®æ•°é‡ï¼Œé¿å…è¿‡é•¿
                max_entries = 8
                if len(bullet_points) > max_entries:
                    bullet_points = bullet_points[:max_entries]
                
                # æ·»åŠ bullet pointç¬¦å·
                formatted_points = []
                for point in bullet_points:
                    # ç¡®ä¿æ¯ä¸ªæ¡ç›®ä¸ä¼šå¤ªé•¿
                    if len(point) > 200:
                        point = point[:197] + "..."
                    formatted_points.append(f"â€¢ {point}")
                
                return '\n'.join(formatted_points)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ¡ç›®ï¼Œè¿”å›åŸå§‹æ¸…ç†åçš„æ–‡æœ¬
                lines = clean_text.split('\n')
                cleaned_lines = []
                
                for line in lines:
                    line = line.strip()
                    # è¿‡æ»¤æ‰åªåŒ…å«ç‰¹æ®Šå­—ç¬¦ã€æ•°å­—æˆ–å¾ˆçŸ­çš„è¡Œ
                    if line and len(line) > 3 and not re.match(r'^[^\w\u4e00-\u9fff]*$', line):
                        cleaned_lines.append(line)
                
                # ç”¨æ¢è¡Œç¬¦è¿æ¥ä¸åŒå†…å®¹
                result = '\n'.join(cleaned_lines)
                
                # ç§»é™¤å¤šä½™çš„è¿ç»­æ¢è¡Œç¬¦
                result = re.sub(r'\n{3,}', '\n\n', result)
                
                return result.strip()
            
        except Exception as e:
            logger.error(f"Error cleaning description: {e}")
            return description
    
    def extract_key_points(self, description: str) -> list:
        """ä»æè¿°ä¸­æå–å…³é”®è¦ç‚¹"""
        try:
            # ç®€å•çš„å…³é”®è¯æå–é€»è¾‘
            key_indicators = [
                'é‡ç‚¹', 'è¦ç‚¹', 'æ ¸å¿ƒ', 'å…³é”®', 'é‡è¦',
                'æ–°åŠŸèƒ½', 'æ›´æ–°', 'å‘å¸ƒ', 'çªç ´', 'æŠ€æœ¯',
                'AI', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ',
                'æ¨¡å‹', 'ç®—æ³•', 'æ•°æ®', 'åº”ç”¨'
            ]
            
            points = []
            lines = description.split('\n')
            
            for line in lines:
                line = line.strip()
                if any(indicator in line for indicator in key_indicators) and len(line) > 10:
                    points.append(line)
            
            return points[:5]  # è¿”å›æœ€å¤š5ä¸ªè¦ç‚¹
            
        except Exception as e:
            logger.error(f"Error extracting key points: {e}")
            return []
