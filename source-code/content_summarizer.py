import requests
import logging
from typing import Optional, Dict
from bs4 import BeautifulSoup
from config import HEADERS

logger = logging.getLogger(__name__)

class ContentSummarizer:
    """è§†é¢‘å†…å®¹æ€»ç»“å™¨"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update(HEADERS)
    
    def extract_video_info(self, video_detail: Dict) -> Dict:
        """ä»è§†é¢‘è¯¦æƒ…ä¸­æå–å…³é”®ä¿¡æ¯"""
        try:
            # åŸºæœ¬ä¿¡æ¯
            title = video_detail.get('title', '')
            desc = video_detail.get('desc', '')
            duration = video_detail.get('duration', 0)
            view_count = video_detail.get('stat', {}).get('view', 0)
            
            # æ ‡ç­¾ä¿¡æ¯
            tags = [tag.get('tag_name', '') for tag in video_detail.get('tag', [])]
            
            # åˆ†Pä¿¡æ¯ (å¦‚æœæœ‰)
            pages = video_detail.get('pages', [])
            
            return {
                'title': title,
                'description': desc,
                'duration': duration,
                'view_count': view_count,
                'tags': tags,
                'pages': len(pages),
                'has_multiple_parts': len(pages) > 1
            }
            
        except Exception as e:
            logger.error(f"Error extracting video info: {e}")
            return {}
    
    def generate_summary(self, video: Dict, video_detail: Optional[Dict] = None) -> str:
        """ç”Ÿæˆè§†é¢‘å†…å®¹æ‘˜è¦"""
        try:
            title = video.get('title', '')
            description = video.get('description', '')
            video_url = video.get('video_url', '')
            
            # å¦‚æœæœ‰è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨æ›´ä¸°å¯Œçš„æè¿°
            if video_detail:
                video_info = self.extract_video_info(video_detail)
                desc = video_info.get('description', description)
                tags = video_info.get('tags', [])
                
                # æ„å»ºæ›´è¯¦ç»†çš„æ‘˜è¦
                summary_parts = []
                
                # æ ‡é¢˜
                summary_parts.append(f"ğŸ“º **{title}**")
                
                # æè¿° (æ¸…ç†åçš„å†…å®¹ï¼Œä¿æŒæ¢è¡Œæ ¼å¼)
                if desc and desc.strip():
                    clean_desc = self._clean_description(desc)
                    if clean_desc:
                        # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œä½†ä¿æŒå®Œæ•´æ€§
                        if len(clean_desc) > 300:
                            # æ‰¾åˆ°æœ€è¿‘çš„å¥å·æˆ–æ¢è¡Œç¬¦æ¥æˆªæ–­
                            truncate_pos = clean_desc.find('\n', 250)
                            if truncate_pos == -1:
                                truncate_pos = clean_desc.find('ã€‚', 250)
                            if truncate_pos != -1:
                                clean_desc = clean_desc[:truncate_pos + 1] + "..."
                            else:
                                clean_desc = clean_desc[:300] + "..."
                        summary_parts.append(f"\n\nğŸ“‹ **å†…å®¹æ¦‚è¦ï¼š**\n{clean_desc}")
                
                # æ ‡ç­¾
                if tags:
                    relevant_tags = [tag for tag in tags[:5] if tag]  # å–å‰5ä¸ªæ ‡ç­¾
                    if relevant_tags:
                        summary_parts.append(f"\n\nğŸ·ï¸ **ç›¸å…³æ ‡ç­¾ï¼š** {' | '.join(relevant_tags)}")
                
                # è§‚çœ‹é“¾æ¥ - è¿™æ˜¯å”¯ä¸€ä¿ç•™çš„é“¾æ¥
                summary_parts.append(f"\n\nğŸ”— **è§‚çœ‹é“¾æ¥ï¼š** {video_url}")
                
                return "".join(summary_parts)
            
            else:
                # ç®€å•æ‘˜è¦
                summary_parts = []
                summary_parts.append(f"ğŸ“º **{title}**")
                
                if description and description.strip():
                    clean_desc = self._clean_description(description)
                    if clean_desc:
                        if len(clean_desc) > 200:
                            # æ‰¾åˆ°æœ€è¿‘çš„å¥å·æˆ–æ¢è¡Œç¬¦æ¥æˆªæ–­
                            truncate_pos = clean_desc.find('\n', 150)
                            if truncate_pos == -1:
                                truncate_pos = clean_desc.find('ã€‚', 150)
                            if truncate_pos != -1:
                                clean_desc = clean_desc[:truncate_pos + 1] + "..."
                            else:
                                clean_desc = clean_desc[:200] + "..."
                        summary_parts.append(f"\n\nğŸ“‹ **å†…å®¹æ¦‚è¦ï¼š**\n{clean_desc}")
                
                # è§‚çœ‹é“¾æ¥ - è¿™æ˜¯å”¯ä¸€ä¿ç•™çš„é“¾æ¥
                summary_parts.append(f"\n\nğŸ”— **è§‚çœ‹é“¾æ¥ï¼š** {video_url}")
                
                return "".join(summary_parts)
                
        except Exception as e:
            logger.error(f"Error generating summary: {e}")
            return f"ğŸ“º {video.get('title', 'æœªçŸ¥æ ‡é¢˜')}\nğŸ”— {video.get('video_url', '')}"
    
    def _clean_description(self, description: str) -> str:
        """æ¸…ç†æè¿°æ–‡æœ¬"""
        try:
            import re
            
            # ç§»é™¤HTMLæ ‡ç­¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if '<' in description and '>' in description:
                soup = BeautifulSoup(description, 'html.parser')
                clean_text = soup.get_text()
            else:
                clean_text = description
            
            # ç§»é™¤æ‰€æœ‰é“¾æ¥ä¿¡æ¯
            # ç§»é™¤ http/https é“¾æ¥
            clean_text = re.sub(r'https?://[^\s\n\r\t]+', ' ', clean_text)
            
            # ç§»é™¤ www å¼€å¤´çš„é“¾æ¥
            clean_text = re.sub(r'www\.[^\s\n\r\t]+', ' ', clean_text)
            
            # ç§»é™¤é‚®ç®±
            clean_text = re.sub(r'\S+@\S+\.\S+', ' ', clean_text)
            
            # ç§»é™¤Bç«™ç›¸å…³é“¾æ¥æ ¼å¼
            clean_text = re.sub(r'BV[0-9A-Za-z]+', ' ', clean_text)
            clean_text = re.sub(r'av[0-9]+', ' ', clean_text)
            
            # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
            clean_text = re.sub(r'\s+', ' ', clean_text)
            
            # ç§»é™¤ä¸€äº›å¸¸è§çš„æ— ç”¨ä¿¡æ¯
            unwanted_phrases = [
                'ç‚¹å‡»å±•å¼€',
                'å±•å¼€å…¨éƒ¨',
                'æ”¶èµ·',
                'æ›´å¤šç²¾å½©å†…å®¹',
                'å…³æ³¨æˆ‘ä»¬',
                'è®¢é˜…é¢‘é“',
                'é“¾æ¥ï¼š',
                'ç½‘å€ï¼š',
                'åœ°å€ï¼š',
                'å®˜ç½‘ï¼š',
                'è¯¦æƒ…ï¼š',
                'æŸ¥çœ‹æ›´å¤š',
                'ç‚¹å‡»æŸ¥çœ‹',
                'å¤åˆ¶é“¾æ¥',
                'åˆ†äº«é“¾æ¥'
            ]
            
            for phrase in unwanted_phrases:
                clean_text = clean_text.replace(phrase, '')
            
            # åˆ†æ®µå¤„ç†ï¼Œä¿æŒæ¢è¡Œ
            lines = clean_text.split('\n')
            cleaned_lines = []
            
            for line in lines:
                line = line.strip()
                # è¿‡æ»¤æ‰åªåŒ…å«ç‰¹æ®Šå­—ç¬¦ã€æ•°å­—æˆ–å¾ˆçŸ­çš„è¡Œ
                if line and len(line) > 3 and not re.match(r'^[^\w\u4e00-\u9fff]*$', line):
                    cleaned_lines.append(line)
            
            # ç”¨æ¢è¡Œç¬¦è¿æ¥ä¸åŒå†…å®¹
            result = '\n'.join(cleaned_lines)
            
            # ç§»é™¤å¤šä½™çš„è¿ç»­æ¢è¡Œç¬¦
            result = re.sub(r'\n{3,}', '\n\n', result)
            
            return result.strip()
            
        except Exception as e:
            logger.error(f"Error cleaning description: {e}")
            return description
    
    def extract_key_points(self, description: str) -> list:
        """ä»æè¿°ä¸­æå–å…³é”®è¦ç‚¹"""
        try:
            # ç®€å•çš„å…³é”®è¯æå–é€»è¾‘
            key_indicators = [
                'é‡ç‚¹', 'è¦ç‚¹', 'æ ¸å¿ƒ', 'å…³é”®', 'é‡è¦',
                'æ–°åŠŸèƒ½', 'æ›´æ–°', 'å‘å¸ƒ', 'çªç ´', 'æŠ€æœ¯',
                'AI', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ',
                'æ¨¡å‹', 'ç®—æ³•', 'æ•°æ®', 'åº”ç”¨'
            ]
            
            points = []
            lines = description.split('\n')
            
            for line in lines:
                line = line.strip()
                if any(indicator in line for indicator in key_indicators) and len(line) > 10:
                    points.append(line)
            
            return points[:5]  # è¿”å›æœ€å¤š5ä¸ªè¦ç‚¹
            
        except Exception as e:
            logger.error(f"Error extracting key points: {e}")
            return []
